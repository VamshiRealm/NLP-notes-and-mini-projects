{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7a65588-81b7-4515-a073-8315e26e156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the images\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image1 = cv2.imread(r\"C:\\Users\\vamsh\\Desktop\\NLP Images\\Image1.jpg\")\n",
    "image2 = cv2.imread(r\"C:\\Users\\vamsh\\Desktop\\NLP Images\\Image2.jpg\")\n",
    "image3 = cv2.imread(r\"C:\\Users\\vamsh\\Desktop\\NLP Images\\Image3.jpg\")\n",
    "image4 = cv2.imread(r\"C:\\Users\\vamsh\\Desktop\\NLP Images\\Image4.jpg\")\n",
    "image5 = cv2.imread(r\"C:\\Users\\vamsh\\Desktop\\NLP Images\\Image5.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1977de12-b23e-4513-9d22-8360c3a34079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204, 306, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134c2ec5-13cf-43c2-8104-bc2c2629d0c2",
   "metadata": {},
   "source": [
    "# Step 1: Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4106df38-9463-4fbc-b6df-1bb7ab50863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1: Convert Images to grayscale\n",
    "\n",
    "img1g = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "img2g = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "img3g = cv2.cvtColor(image3, cv2.COLOR_BGR2GRAY)\n",
    "img4g = cv2.cvtColor(image4, cv2.COLOR_BGR2GRAY)\n",
    "img5g = cv2.cvtColor(image5, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bd90c6b-7f79-4e97-a80f-ad4a7214a3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(204, 306)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d04a4537-a904-4bbb-b37c-6b699e140ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: resize all images to uniform shape : (256 x 256)\n",
    "\n",
    "img1rsd = cv2.resize(img1g, (256,256))\n",
    "img2rsd = cv2.resize(img2g, (256,256))\n",
    "img3rsd = cv2.resize(img3g, (256,256))\n",
    "img4rsd = cv2.resize(img4g, (256,256))\n",
    "img5rsd = cv2.resize(img5g, (256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8d0153a-35bb-4a03-8629-e4f687a185c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1rsd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9311a9e1-8d8e-4f80-a21d-e9d6e6b23f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3: Normalize the pixel values of images to range of [0,1] Let's use .astype()\n",
    "# normalized = denoised.astype(np.float32) / 255.0\n",
    "normImg1 = img1rsd.astype(np.float32) / 255.0\n",
    "normImg2 = img2rsd.astype(np.float32) / 255.0\n",
    "normImg3 = img3rsd.astype(np.float32) / 255.0\n",
    "normImg4 = img4rsd.astype(np.float32) / 255.0\n",
    "normImg5 = img5rsd.astype(np.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d98496bb-e129-492b-b3c4-1aa2896d234d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7921569 , 0.7921569 , 0.7921569 , ..., 0.80784315, 0.8156863 ,\n",
       "        0.81960785],\n",
       "       [0.7921569 , 0.7921569 , 0.7921569 , ..., 0.80784315, 0.8156863 ,\n",
       "        0.81960785],\n",
       "       [0.7921569 , 0.7921569 , 0.7921569 , ..., 0.80784315, 0.8156863 ,\n",
       "        0.81960785],\n",
       "       ...,\n",
       "       [0.59607846, 0.59607846, 0.59607846, ..., 0.6862745 , 0.7058824 ,\n",
       "        0.7137255 ],\n",
       "       [0.59607846, 0.59607846, 0.59607846, ..., 0.6901961 , 0.7058824 ,\n",
       "        0.7137255 ],\n",
       "       [0.59607846, 0.59607846, 0.59607846, ..., 0.69803923, 0.70980394,\n",
       "        0.7137255 ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normImg1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b63a245-69e4-46aa-bbb4-62018b8ee6ef",
   "metadata": {},
   "source": [
    "# Step 2: Image Manipulation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2332539b-4b9d-423d-991a-4514820dbb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying image augmentation techniques such as rotating the image by 30, 60, and 90 degrees\n",
    "# Rotating the Image\n",
    "\n",
    "rows, cols = normImg1.shape\n",
    "center = (cols/2, rows/2)\n",
    "rotation_matrix = cv2.getRotationMatrix2D(center, 60, 1) # center, angle, sortion\n",
    "rotated_image = cv2.warpAffine(normImg1, rotation_matrix, (cols, rows))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dc7d762-f3a2-478e-9f8f-df825424a64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Flip the image horizontally and vertically.\n",
    "# flipped_image = cv2.flip(image, 1)\n",
    "img1HoriFlip = cv2.flip(rotated_image, 1) #flippping Horizontally\n",
    "img1VertFlip = cv2.flip(rotated_image, 0)  #flipping vertically\n",
    "img1BothFlip = cv2.flip(rotated_image, -1)  #flipping both horizontally and vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "439eb2e6-39b0-44ee-8364-8e619dbaa963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting the contrast and brightness of the image.\n",
    "\n",
    "adjusted_img = cv2.convertScaleAbs(rotated_image, alpha = 0.5, beta=200) #alpha : contrast, beta: brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c614200f-effd-4ac8-909e-c81136a6cff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1fd1b9-8fa4-442b-ac15-93de1a2e008a",
   "metadata": {},
   "source": [
    "# Step 3: Transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dadba278-bd0b-48bf-ae09-295d2d0edd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Geometric Transformations\n",
    "\n",
    "# Translation: Shifting the image\n",
    "def translate_image(image, tx, ty):\n",
    "    rows, cols = image.shape\n",
    "    translation_matrix = np.float32([[1, 0, tx], [0, 1, ty]])  # tx, ty are the shifts along x and y axes\n",
    "    translated_image = cv2.warpAffine(image, translation_matrix, (cols, rows))\n",
    "    return translated_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "428ac16b-6949-403e-875e-59fab6e86257",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_image = translate_image(normImg1, tx=50, ty=30)  # Example: shift right by 50 pixels and down by 30 pixels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f69a88dd-740d-4e8b-8129-b55f874ffa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling: Resizing the image\n",
    "def scale_image(image, scale_factor_x, scale_factor_y):\n",
    "    rows, cols = image.shape\n",
    "    scaled_image = cv2.resize(image, None, fx=scale_factor_x, fy=scale_factor_y, interpolation=cv2.INTER_LINEAR)\n",
    "    return scaled_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35de3e09-cbcd-41ef-9663-2d119033bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_image = scale_image(normImg1, scale_factor_x=1.5, scale_factor_y=1.5)  # Example: 1.5x scale on both axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5415c40c-2b90-4af6-96f8-50225e0e567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Shearing: Distorting the image\n",
    "def shear_image(image, shear_factor_x, shear_factor_y):\n",
    "    rows, cols = image.shape\n",
    "    shearing_matrix = np.float32([[1, shear_factor_x, 0], [shear_factor_y, 1, 0]])\n",
    "    sheared_image = cv2.warpAffine(image, shearing_matrix, (cols, rows))\n",
    "    return sheared_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a05fa19c-3556-4862-9de0-5acdac8a4225",
   "metadata": {},
   "outputs": [],
   "source": [
    "sheared_image = shear_image(normImg1, shear_factor_x=0.2, shear_factor_y=0.1)  # Example: shear along x and y axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62816315-813b-4074-ab10-ec702685acd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a5ff287-9324-4605-8e4c-2033d70c53b5",
   "metadata": {},
   "source": [
    "# Displaying all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82df4dbb-9f61-4e18-9001-4add7de81321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escape key pressed, closing window...\n"
     ]
    }
   ],
   "source": [
    "cv2.imshow('Original Image', image1)\n",
    "cv2.imshow('Grayscale Image', img1g)\n",
    "cv2.imshow('Resized Image', img1rsd)\n",
    "cv2.imshow('Normalized Image', normImg1)\n",
    "cv2.imshow('Rotated Image', rotated_image)\n",
    "cv2.imshow('Horizontal Flip Image', img1HoriFlip)\n",
    "cv2.imshow('Vertical Flip Image', img1VertFlip)\n",
    "cv2.imshow('Adjusted Image', adjusted_img)\n",
    "cv2.imshow('Translated Image', translated_image)\n",
    "cv2.imshow('Scaled Image', scaled_image)\n",
    "\n",
    "\n",
    "key = cv2.waitKey(0)\n",
    "if key == 27: #ASCII value of 'esc' is 27\n",
    "    print(\"Escape key pressed, closing window...\")\n",
    "else:\n",
    "    print(f\"Key pressed: {key}\")\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecafaac0-1290-4efb-91ca-1be0b169787f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
